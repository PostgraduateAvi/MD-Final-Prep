# PDF Token Agent Setup Instructions

## Overview
The PDF Token Agent automatically scans every PDF file in the `PDFs/Harrison_Textbooks` directory via GitHub API, extracts all text, tokenizes every individual word, builds a token summary covering all unique words found, and outputs the complete token summary to `token_summary.txt` at the repository root.

## Dependencies
The agent requires the following Python packages:

### Required
- **PyPDF2==3.0.1** - For PDF text extraction
- **requests** - For GitHub API access (usually pre-installed with Python)

### Installation
Install the required dependencies with:

```bash
pip install PyPDF2==3.0.1
```

Or install all project dependencies:

```bash
pip install -r requirements.txt
```

## Usage

### Single Command Execution
Run the agent with a single command from the repository root:

```bash
python3 pdf_token_agent.py
```

### What It Does
1. **GitHub API Access**: Connects to the GitHub repository and accesses the `PDFs/Harrison_Textbooks` directory
2. **PDF Processing**: Downloads and processes each PDF file in the directory
3. **Text Extraction**: Extracts all text content from each PDF using PyPDF2
4. **Word Tokenization**: Breaks down text into individual words (alphabetic characters only)
5. **Unique Word Collection**: Builds a comprehensive list of all unique words found
6. **Output Generation**: Saves all unique words to `token_summary.txt` in alphabetical order

### Output
- **File**: `token_summary.txt` (created at repository root)
- **Format**: Plain text file with one unique word per line
- **Organization**: Alphabetically sorted for easy reference
- **Statistics**: Header includes total count and processing details

### Example Output Structure
```
# Token Summary - Harrison's Textbooks PDF Collection
# Generated by PDF Token Agent
# Total unique words: 82,302
# Repository: PostgraduateAvi/MD-Final-Prep
# Source directory: PDFs/Harrison_Textbooks
#
# Unique words (alphabetically sorted):
#

aa
aaa
aaadna
...
zygotic
zygourakis
zz
```

## Features
- **GitHub API Integration**: Accesses PDFs directly from the repository without local storage
- **Robust PDF Processing**: Handles various PDF formats and structures
- **Memory Efficient**: Uses sets for automatic duplicate removal
- **Error Handling**: Graceful handling of network issues and corrupted files
- **Progress Tracking**: Real-time logging of processing status
- **Comprehensive Output**: Includes metadata and statistics in the output file

## Technical Details
- **Tokenization Method**: Regex-based word extraction (`[a-zA-Z]+`)
- **Word Filtering**: Excludes words shorter than 2 characters or longer than 50 characters
- **Case Handling**: Converts all words to lowercase for consistency
- **Duplicate Handling**: Automatic deduplication using Python sets
- **Sorting**: Alphabetical sorting for consistent output

## Troubleshooting

### Common Issues
1. **PyPDF2 Import Error**: Install PyPDF2 with `pip install PyPDF2==3.0.1`
2. **Network Issues**: Check internet connection for GitHub API access
3. **Permission Errors**: Ensure write permissions in the repository directory

### Verification
After running the agent, verify the output:
```bash
# Check if file was created
ls -la token_summary.txt

# Check word count
wc -l token_summary.txt

# View first few words
head -20 token_summary.txt

# View last few words
tail -10 token_summary.txt
```

## Notes
- The agent processes approximately 183.9 MB of PDF content
- Processing time varies based on network speed and system resources
- The generated token summary is suitable for language model training and NLP applications
- All words are extracted and deduplicated across the entire PDF collection